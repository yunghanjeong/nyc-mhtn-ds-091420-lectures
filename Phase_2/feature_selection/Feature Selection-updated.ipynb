{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Selection\n",
    "\n",
    "Feature selection is the process of selecting a subset of relevant features for use in model construction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Top reasons to use feature selection are:\n",
    "* It enables the machine learning algorithm to train faster.\n",
    "* It reduces the complexity of a model and makes it easier to interpret.\n",
    "* It improves the accuracy of a model if the right subset is chosen.\n",
    "* It reduces overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Import the packages we will use for this notebook***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Set up or initial dataframe by removing variable and transforming others.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/nyc-mhtn-ds-051120-lectures/master/Mod_2/model_evaluation/resources/movie_dataset_us.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['duration'],inplace=True)\n",
    "\n",
    "features=['budget', 'duration','actor_1_facebook_likes','cast_total_facebook_likes', 'PG', 'PG-13', 'R',\n",
    "       'yr_old']\n",
    "\n",
    "df_features = df[features]\n",
    "\n",
    "target = df['gross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_features.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, target, random_state=9,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my training and testing datasets, I am going to apply my feature scaler to the dataset.  \n",
    "\n",
    "**Why am I scaling my data after the train-test split and not before?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#transform the training data\n",
    "X_train = pd.DataFrame(data=scaler.transform(X_train), columns=df_features.columns)\n",
    "\n",
    "#transform the testing dat\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm = lm.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lm.predict(X_train)\n",
    "\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use fitted model to predict on the test examples\n",
    "y_test_pred = lm.predict(X_test)\n",
    "\n",
    "#evaluate the predictions on the test examples\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plot the residuals after fitting a linear model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.residplot( y_test, y_test_pred,lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Will our model perform better if we try to predict the log of the gross instead?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the natural log of the target variable\n",
    "y_log = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_log = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_log = lm_log.fit(X_train, y_log)\n",
    "\n",
    "log_train_pred = lm_log.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_train_pred the predictions to get them on the same original scale \n",
    "y_train_pred = np.exp(log_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, log_train_pred))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_test_pred = lm_log.predict(X_test)\n",
    "#exponentiate the predictions to get them on the same original scale \n",
    "log_test_pred = np.exp(log_test_pred)\n",
    "log_test_rmse = np.sqrt(metrics.mean_squared_error(y_test, log_test_pred))\n",
    "\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , log_test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the new model to predict the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lm_log.predict(X_test)\n",
    "\n",
    "\n",
    "#our model predcicte the log of gross, so now we must exponentiate to get the value in $\n",
    "y_test_pred = np.exp(y_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Polynomial and Interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly2_data = poly_2.fit_transform(df_features)\n",
    "poly2_columns = poly_2.get_feature_names(df_features.columns)\n",
    "df_poly2 = pd.DataFrame(poly2_data, columns=poly2_columns)\n",
    "df_poly2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_poly2, target, random_state=9,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "# fit the scaler to the training data\n",
    "scaler2.fit(X_train)\n",
    "\n",
    "#transform the training data\n",
    "X_train = pd.DataFrame(data=scaler2.transform(X_train), columns=df_poly2.columns)\n",
    "\n",
    "#transform the testing dat\n",
    "X_test = pd.DataFrame(data=scaler2.transform(X_test), columns=df_poly2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a linear regression object\n",
    "lm_2 = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_2 = lm_2.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lm_2.predict(X_train)\n",
    "\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fitted model to predict on test data\n",
    "y_pred = lm_2.predict(X_test)\n",
    "\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given the difference in RMSE between our test and training sets, what can we say about this model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly3_data = poly_3.fit_transform(df_features)\n",
    "poly3_columns = poly_3.get_feature_names(df_features.columns)\n",
    "df_poly3 = pd.DataFrame(poly3_data, columns=poly3_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_poly3, target, random_state=9,test_size=0.2)\n",
    "scaler3 = StandardScaler()\n",
    "# fit the scaler to the training data\n",
    "scaler3.fit(X_train)\n",
    "\n",
    "#transform the training data\n",
    "X_train = pd.DataFrame(data=scaler3.transform(X_train), columns=df_poly3.columns)\n",
    "\n",
    "#transform the testing dat\n",
    "X_test = pd.DataFrame(data=scaler3.transform(X_test), columns=df_poly3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a linear regression object\n",
    "lm_3 = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_3 = lm_3.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lm_3.predict(X_train)\n",
    "\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fitted model to predict on test data\n",
    "y_pred = lm_3.predict(X_test)\n",
    "\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given the difference in RMSE between our test and training sets, what can we say about this model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Types of Feature Selection\n",
    "\n",
    "* Filter Methods\n",
    "* Wrapper Methods\n",
    "* Embedded Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Filter Methods\n",
    "Filter feature selection methods apply a statistical measure to assign a scoring to each feature. The features are ranked by the score and either selected to be kept or removed from the dataset. The methods are often univariate and consider the feature independently, or with regard to the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./resources/Filter_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/why-how-and-when-to-apply-feature-selection-e9c69adfabf2\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Examples:** \n",
    "* F-Test\n",
    "* Chi squared test \n",
    "* Information gain \n",
    "* Correlation coefficient scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./resources/FS1.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Variables based on correlation coefficient\n",
    "\n",
    "When using this process to find features to remove, I think it is easier/better to do before creating our polynomials or interactions. So I'm going to look at the original 8 features, and search for high correlation in those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_8, X_test_8, y_train_8, y_test_8 = train_test_split(df_features, target, random_state=9,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X_train_8.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_train_8.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index of feature columns with correlation greater than 0.90\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "#if you change inplace to True it will go through and drop all of those columns from the dataset\n",
    "X_train_8.drop(columns=to_drop, inplace=False)\n",
    "X_test_8.drop(columns=to_drop, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Inflation Factor (VIF) \n",
    "\n",
    "VIFis a measure of colinearity among predictor variables within a multiple regression. The variance inflation factor for the estimated regression coefficient $b_j$ — denoted $VIF_j$ —is just the factor by which the variance of $b_j$ is \"inflated\" by the existence of correlation among the predictor variables in the model.In particular, the variance inflation factor for the jth predictor is:\n",
    "\n",
    "$$VIF_j=\\frac{1}{1-R_{j}^{2}}$$\n",
    "\n",
    "\n",
    "where $R^2_j$  is the $R^2$-value obtained by regressing the jth predictor on the remaining predictors. \n",
    "\n",
    "\n",
    "Inspect the factors for each predictor variable, if the VIF is between 5-10, multicolinearity is likely present and you should consider dropping the variable.\n",
    "\n",
    "https://online.stat.psu.edu/stat462/node/180/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[variance_inflation_factor(X_train.values, i) for i in range(X_train_8.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df_features.values, i) for i in range(df_features.shape[1])]\n",
    "vif[\"features\"] = df_features.columns\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.corrwith(target).abs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Best features based on some statistical measure\n",
    "\n",
    "Scikit-learn provides the Select K best features using F-Test.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  F Test\n",
    "\n",
    "F Test is a statistical test used to compare between models and check if the difference is significant between the model.\n",
    "\n",
    "F-Test does a hypothesis testing model X and Y where X is a model created by just a constant and Y is the model created by a constant and a feature.\n",
    "\n",
    "The least square errors in both the models are compared and checks if the difference in errors between model X and Y are significant or introduced by chance.\n",
    "\n",
    "F-Test is useful in feature selection as we get to know the significance of each feature in improving the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I am using the F-test to select the 20 top varaibles for this model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "\n",
    "selector = SelectKBest(f_regression, k=20)\n",
    "\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_train.columns[selector.get_support()]\n",
    "removed_columns = X_train.columns[~selector.get_support()]\n",
    "# X_train = X_train[selected_columns]\n",
    "# X_test = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(removed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_kbest = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_kbest = lm_kbest.fit(X_train[selected_columns], y_train)\n",
    "\n",
    "y_train_kbest = lm_kbest.predict(X_train[selected_columns])\n",
    "\n",
    "\n",
    "trainK_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_kbest))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainK_rmse)\n",
    "\n",
    "y_kbest = lm_kbest.predict(X_test[selected_columns])\n",
    "\n",
    "testK_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_kbest))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testK_rmse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: ', test_rmse, '\\n',\n",
    "      \"KBest:   \", testK_rmse,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrapper Methods\n",
    "\n",
    "Wrapper methods consider the selection of a set of features as a search problem, where different combinations are prepared, evaluated and compared to other combinations. A predictive model is used to evaluate a combination of features and assign a score based on model accuracy.\n",
    "\n",
    "The search process may be methodical such as a best-first search, it may stochastic such as a random hill-climbing algorithm, or it may use heuristics, like forward and backward passes to add and remove features.\n",
    "\n",
    "Wrapper Methods promises you a best set of features with a extensive greedy search.\n",
    "\n",
    "But the main drawbacks of wrapper methods is the sheer amount of models that needs to be trained. It is computationally very expensive and is infeasible with large number of features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./resources/Wrapper_1.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "\n",
    "An example if a wrapper method is the recursive feature elimination algorithm.\n",
    "\n",
    "As the name suggests, this method eliminates worst performing features on a particular model one after the other until the best subset of features are known.\n",
    "\n",
    "\n",
    "Recursive elimination eliminates the least explaining features one after the other.\n",
    "For data with n features,\n",
    "\n",
    "- On first round ‘n-1’ models are created with combination of all features except one. The least performing feature is removed\n",
    "\n",
    "- On second round ‘n-2’ models are created by removing another feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./resources/rfe_graph.png' width=500/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recursive feature eliminator that scores features by mean squared errors\n",
    "selector = RFECV(estimator=ols, step=1, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit recursive feature eliminator \n",
    "selector.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rfe = X_train.columns[selector.support_]\n",
    "removed_rfe = X_train.columns[~selector.support_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(removed_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(selected_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_rfe = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_rfe = lm_rfe.fit(X_train[selected_rfe], y_train)\n",
    "\n",
    "y_rfe = lm_rfe.predict(X_train[selected_rfe])\n",
    "\n",
    "\n",
    "trainRFE_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_rfe))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainRFE_rmse)\n",
    "\n",
    "y_pred_rfe = lm_rfe.predict(X_test[selected_rfe])\n",
    "\n",
    "testRFE_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred_rfe))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testRFE_rmse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: ', test_rmse, '\\n',\n",
    "      \"KBest:   \", testK_rmse,'\\n',\n",
    "      \"RFE:     \", testRFE_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embedded Methods\n",
    "\n",
    "Embedded methods learn which features best contribute to the accuracy of the model while the model is being created. The most common type of embedded feature selection methods are regularization methods.\n",
    "\n",
    "Regularization methods are also called penalization methods that introduce additional constraints into the optimization of a predictive algorithm (such as a regression algorithm) that bias the model toward lower complexity (fewer coefficients).\n",
    "\n",
    "Examples of regularization algorithms are the LASSO, Elastic Net and Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./resources/Embedded_1.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plot to compare the size of all of our coefficients form our final model created by RFE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(data=lm_rfe.coef_ ).T\n",
    "coef.columns = selected_rfe\n",
    "\n",
    "model_coef = coef.T.sort_values(by=0).T\n",
    "model_coef.plot(kind='bar', title='Modal Coefficients', legend=False, figsize=(16,8),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.1, normalize=False)\n",
    "\n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "train_rmse_lasso01 = metrics.mean_absolute_error(y_train, y_train_lasso01)\n",
    "test_rmse_lasso01 = np.sqrt(metrics.mean_squared_error(y_test, y_test_lasso01))\n",
    "print('Training Error: '+ str(train_rmse_lasso01) )\n",
    "print('Testing Error: '+ str(test_rmse_lasso01) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef01 = pd.DataFrame(data=lasso.coef_).T\n",
    "lasso_coef01.columns = X_train.columns\n",
    "lasso_coef01 = lasso_coef01.T.sort_values(by=0).T\n",
    "lasso_coef01.plot(kind='bar', title='Modal Coefficients', legend=False, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = lasso_coef01.T\n",
    "\n",
    "coeff_df[coeff_df[0]==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df[coeff_df[0]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: \\t', test_rmse, '\\n',\n",
    "      \"KBest: \\t\", testK_rmse, '\\n',\n",
    "      \"RFE: \\t \\t\", testRFE_rmse, '\\n', \n",
    "      \"Lasso 0.01: \\t\",  test_rmse_l01, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: when do we use which method?\n",
    "\n",
    "Lasso probably appears to be the easiest method to use to select the features of your model. So why would you bother with any of the other methods?  \n",
    "\n",
    "A Lasso algorithm is only for linear models, and you might rather use a different machine learning algorithm like K-Nearest Neighbors. Therefore, a filter or wrapper method could be used to perform your feature selection.\n",
    "\n",
    "You might start off with hundreds or thousands of features that you want to select from. This could take a while to run a wrapper or embedded method, so you can use a filter method first to reduce your model size and have it run more quickly.  \n",
    "\n",
    "Finally you can also combine these methods together. So you might start with a filter method to remove some of the features that are obviously non-impactful to our target variable, then run a wrapper or embedded method to finish the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model:\n",
    "\n",
    "During this whole process we were only using a percentage of our data to train the model so that we can do test train split.  \n",
    "\n",
    "Now we have identified the process that generate the model that performs the best, we want to go back and fit it to all available data to get a final model.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "#fit and transform the  data\n",
    "df_poly3 = pd.DataFrame(data=scaler.fit_transform(df_poly3), columns=df_poly3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_regression, k=20)\n",
    "\n",
    "selector.fit(df_poly3, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_train.columns[selector.get_support()]\n",
    "removed_columns = X_train.columns[~selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_final = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_final = lm_final.fit(df_poly3[selected_columns], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_final.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that final model, we want to save it to use again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle_out = open(\"model.pickle\",\"wb\")\n",
    "pickle.dump(lm_final, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
